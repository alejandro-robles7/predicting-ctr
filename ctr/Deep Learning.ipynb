{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning\n",
    "\n",
    "Profits can be heavily impacted by your campaign’s CTR. In this chapter, you’ll learn how deep learning can be used to reduce that risk. You’ll focus on multi-layer perceptron (MLP) and neural network models, and learn how these can be used to capture the complex relationship between variables to more accurately predict CTR. Lastly, you’ll explore how to apply the basics of hyperparameter tuning and regularization to classification models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLPs for CTR\n",
    "In this exercise, you will evaluate both the accuracy score and AUC of the ROC curve for a basic MLP model on the ad CTR dataset. Remember to standardize the features before splitting into training and testing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_pickle\n",
    "\n",
    "df = read_pickle('data/data_ch3.pkl')\n",
    "# # Get non-categorical columns, with a filter\n",
    "num_df = df.select_dtypes(include=['int', 'float'])\n",
    "filter_cols = ['banner_pos', 'hour_of_day']\n",
    "new_df = num_df[num_df.columns[~num_df.columns.isin(filter_cols)]]\n",
    "\n",
    "X = new_df.loc[:, ~new_df.columns.isin(['click'])]\n",
    "y = new_df.click"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.89\n",
      "ROC of AUC curve: 0.4177732379979571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alejandro.robles/Library/Python/3.7/lib/python/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alejandro.robles/Library/Python/3.7/lib/python/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score\n",
    "\n",
    "\n",
    "# Scale features and split into training and testing\n",
    "X = StandardScaler().fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "  X, y, test_size = .2, random_state = 0)\n",
    "\n",
    "# Create classifier and produce predictions\n",
    "clf = MLPClassifier(hidden_layer_sizes = (8, ), max_iter = 100)\n",
    "y_score = clf.fit(X_train, y_train).predict_proba(X_test) \n",
    "y_pred = clf.fit(X_train, y_train).predict(X_test) \n",
    "\n",
    "# Get accuracy and AUC of ROC curve \n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_score[:, 1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(\"Accuracy: %s\" %(accuracy_score(y_test, y_pred)))\n",
    "print(\"ROC of AUC curve: %s\" %(roc_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the accuracy score and AUC of ROC curve seem to be ballpark around that of other classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Varying hyperparameters\n",
    "The number of iterations of training, and the size of hidden layers are two primary hyperparameters that can be varied when working with a MLP classifier. In this exercise, you will vary both separately and note how performance in terms of accuracy and AUC of the ROC curve may vary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alejandro.robles/Library/Python/3.7/lib/python/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alejandro.robles/Library/Python/3.7/lib/python/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alejandro.robles/Library/Python/3.7/lib/python/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for max_iter = 10: 0.89\n",
      "AUC for max_iter = 10: 0.4851889683350357\n",
      "Accuracy for max_iter = 20: 0.89\n",
      "AUC for max_iter = 20: 0.48416751787538304\n",
      "Accuracy for max_iter = 30: 0.89\n",
      "AUC for max_iter = 30: 0.49846782431052095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alejandro.robles/Library/Python/3.7/lib/python/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alejandro.robles/Library/Python/3.7/lib/python/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alejandro.robles/Library/Python/3.7/lib/python/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Loop over various max_iter configurations\n",
    "max_iter_list = [10, 20, 30]\n",
    "for max_iter in max_iter_list:\n",
    "\tclf = MLPClassifier(hidden_layer_sizes = (4, ), \n",
    "                        max_iter = max_iter, random_state = 0)\n",
    "   \t# Extract relevant predictions\n",
    "\ty_score = clf.fit(X_train, y_train).predict_proba(X_test)\n",
    "\ty_pred = clf.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "\t# Get ROC curve metrics\n",
    "\tprint(\"Accuracy for max_iter = %s: %s\" %(\n",
    "      max_iter, accuracy_score(y_test, y_pred)))\n",
    "\tprint(\"AUC for max_iter = %s: %s\" %(\n",
    "      max_iter, roc_auc_score(y_test, y_score[:, 1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alejandro.robles/Library/Python/3.7/lib/python/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for hidden_layer_sizes = (4,): 0.89\n",
      "AUC for hidden_layer_sizes = (4,): 0.4851889683350357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alejandro.robles/Library/Python/3.7/lib/python/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alejandro.robles/Library/Python/3.7/lib/python/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alejandro.robles/Library/Python/3.7/lib/python/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alejandro.robles/Library/Python/3.7/lib/python/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for hidden_layer_sizes = (8,): 0.59\n",
      "AUC for hidden_layer_sizes = (8,): 0.6414708886618998\n",
      "Accuracy for hidden_layer_sizes = (16,): 0.77\n",
      "AUC for hidden_layer_sizes = (16,): 0.5168539325842696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alejandro.robles/Library/Python/3.7/lib/python/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Create and loop over various hidden_layer_sizes configurations\n",
    "hidden_layer_sizes_list = [(4,), (8,), (16,)]\n",
    "for hidden_layer_sizes in hidden_layer_sizes_list:\n",
    "\tclf = MLPClassifier(hidden_layer_sizes = hidden_layer_sizes, \n",
    "                        max_iter = 10, random_state = 0)\n",
    "   \t# Extract relevant predictions\n",
    "\ty_score = clf.fit(X_train, y_train).predict_proba(X_test)\n",
    "\ty_pred = clf.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "\t# Get ROC curve metrics\n",
    "\tprint(\"Accuracy for hidden_layer_sizes = %s: %s\" %(\n",
    "      hidden_layer_sizes, accuracy_score(y_test, y_pred)))\n",
    "\tprint(\"AUC for hidden_layer_sizes = %s: %s\" %(\n",
    "      hidden_layer_sizes, roc_auc_score(y_test, y_score[:, 1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that having more hidden layers seemed to improve performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP Grid Search\n",
    "Hyperparameter tuning can be done by sklearn through providing various input parameters, each of which can be encoded using various functions from numpy. One method of tuning, which exhaustively looks at all combinations of input hyperparameters specified via param_grid, is grid search. In this exercise, you will use grid search to look over the hyperparameters for a MLP classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alejandro.robles/Library/Python/3.7/lib/python/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: \n",
      "0.5386975883986754\n",
      "Best Estimator: \n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(8,), learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_iter=20, momentum=0.9,\n",
      "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "              random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
      "              validation_fraction=0.1, verbose=False, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alejandro.robles/Library/Python/3.7/lib/python/site-packages/sklearn/model_selection/_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "/Users/alejandro.robles/Library/Python/3.7/lib/python/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create list of hyperparameters \n",
    "max_iter = [10, 20]\n",
    "hidden_layer_sizes = [(8, ), (16, )]\n",
    "param_grid = {'max_iter': max_iter, 'hidden_layer_sizes': hidden_layer_sizes}\n",
    "\n",
    "# Use Grid search CV to find best parameters using 4 jobs\n",
    "mlp = MLPClassifier()\n",
    "clf = GridSearchCV(estimator = mlp, param_grid = param_grid, \n",
    "           scoring = 'roc_auc', n_jobs = 4)\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Best Score: \")\n",
    "print(clf.best_score_)\n",
    "print(\"Best Estimator: \")\n",
    "print(clf.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen here, the best AUC is around 0.63 and from the model with the maximum number of iterations (20) and most number of hidden layer units (16)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F-beta score\n",
    "The F-beta score is a weighted harmonic mean between precision and recall, and is used to weight precision and recall differently. It is likely that one would care more about weighting precision over recall, which can be done with a lower beta between 0 and 1. In this exercise, you will calculate the precision and recall of an MLP classifier along with the F-beta score using a beta = 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8215040650406503, Recall: 0.77, F-beta score: 0.8095677674727688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alejandro.robles/Library/Python/3.7/lib/python/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import fbeta_score, precision_score, recall_score\n",
    "\n",
    "# Set up MLP classifier, train and predict\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "  X, y, test_size = .2, random_state = 0)\n",
    "clf = MLPClassifier(hidden_layer_sizes = (16, ), \n",
    "                    max_iter = 10, random_state = 0)\n",
    "y_pred = clf.fit(X_train, y_train).predict(X_test) \n",
    "\n",
    "# Evaluate precision and recall\n",
    "prec = precision_score(y_test, y_pred, average = 'weighted')\n",
    "recall = recall_score(y_test, y_pred, average = 'weighted')\n",
    "fbeta = fbeta_score(y_test, y_pred, beta  = 0.5, average = 'weighted')\n",
    "print(\"Precision: %s, Recall: %s, F-beta score: %s\" %(prec, recall, fbeta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the F-beta score is in between the precision and recall, and closer to the precision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision, ROI, and AUC\n",
    "The return on investment (ROI) can be decomposed into the precision multiplied by a ratio of return to cost. As discussed, it is possible for the precision of a model to be low, even while AUC of the ROC curve is high. If the precision is low, then the ROI will also be low. In this exercise, you will use a MLP to compute a sample ROI assuming a fixed r, the return on a click per number of impressions, and cost, the cost per number of impressions, along with precision and AUC of ROC curve values to check how the three values vary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total ROI: 3.2860162601626013, Precision: 0.8215040650406503, AUC of ROC curve: 0.5168539325842696\n"
     ]
    }
   ],
   "source": [
    "# Get precision and total ROI\n",
    "prec = precision_score(y_test, y_pred, average = 'weighted')\n",
    "r = 0.2\n",
    "cost = 0.05 \n",
    "roi = prec * r / cost\n",
    "\n",
    "# Get AUC\n",
    "roc_auc = roc_auc_score(y_test, y_score[:, 1])\n",
    "\n",
    "print(\"Total ROI: %s, Precision: %s, AUC of ROC curve: %s\" %(\n",
    "  roi, prec, roc_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the ROI was > 1 and the precision and ROC of the AUC are both > 0.65, suggesting this not a case of low precision and high AUC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model comparison warmup\n",
    "In this exercise, you will run a basic comparison of the four categories of outcomes between MLPs and Random Forests using a confusion matrix. This is in preparation for an analysis of all the models we have covered. Doing this warm-up exercise will allow you to compare and contrast the implementation of these models and their evaluation for CTR prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating classifier: Random Forest\n",
      "[[82  7]\n",
      " [ 9  2]]\n",
      "Evaluating classifier: Multi-Layer Perceptron\n",
      "[[43 46]\n",
      " [ 5  6]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alejandro.robles/Library/Python/3.7/lib/python/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/alejandro.robles/Library/Python/3.7/lib/python/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Create the list of models in the order below\n",
    "names = ['Random Forest', 'Multi-Layer Perceptron']\n",
    "classifiers = [RandomForestClassifier(), \n",
    "               MLPClassifier(hidden_layer_sizes = (10, ),\n",
    "                             max_iter = 40)]\n",
    "\n",
    "# Produce a confusion matrix for all classifiers\n",
    "for name, classifier in zip(names, classifiers):\n",
    "  print(\"Evaluating classifier: %s\" %(name))\n",
    "  classifier.fit(X_train, y_train)\n",
    "  y_pred = classifier.predict(X_test)\n",
    "  conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "  print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision for Logistic Regression: 0.7921 \n",
      "Precision for Decision Tree: 0.8414539007092199 \n",
      "Precision for Random Forest: 0.8414539007092199 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alejandro.robles/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/alejandro.robles/Library/Python/3.7/lib/python/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/alejandro.robles/Library/Python/3.7/lib/python/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision for Multi-Layer Perceptron: 0.8282352941176471 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alejandro.robles/Library/Python/3.7/lib/python/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Create list of classifiers\n",
    "names = ['Logistic Regression',  'Decision Tree',\n",
    "         'Random Forest', 'Multi-Layer Perceptron']\n",
    "clfs = [LogisticRegression(), \n",
    "        DecisionTreeClassifier(), RandomForestClassifier(), \n",
    "        MLPClassifier(hidden_layer_sizes = (5, ), max_iter = 40)]\n",
    "\n",
    "# Fit each classifier and evaluate AUC of ROC curve \n",
    "for name, classifier in zip(names, clfs):\n",
    "  classifier.fit(X_train, y_train)\n",
    "  y_score = classifier.predict_proba(X_test)\n",
    "  y_pred = classifier.predict(X_test) \n",
    "  prec = precision_score(y_test, y_pred, average = 'weighted')\n",
    "  print(\"Precision for %s: %s \" %(name, prec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alejandro.robles/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/alejandro.robles/Library/Python/3.7/lib/python/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/alejandro.robles/Library/Python/3.7/lib/python/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROI for Logistic Regression: 3.1684 \n",
      "ROI for Decision Tree: 3.3987368421052633 \n",
      "ROI for Random Forest: 3.3217391304347825 \n",
      "ROI for Multi-Layer Perceptron: 3.608888888888889 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alejandro.robles/Library/Python/3.7/lib/python/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Create list of classifiers\n",
    "names = ['Logistic Regression',  'Decision Tree',\n",
    "         'Random Forest', 'Multi-Layer Perceptron']\n",
    "clfs = [LogisticRegression(), \n",
    "        DecisionTreeClassifier(), RandomForestClassifier(), \n",
    "        MLPClassifier(hidden_layer_sizes = (5, ), max_iter = 50)]\n",
    "  \n",
    "# Produce a classification report for all classifiers\n",
    "for name, classifier in zip(names, clfs):\n",
    "  classifier.fit(X_train, y_train)\n",
    "  y_pred = classifier.predict(X_test) \n",
    "  prec = precision_score(y_test, y_pred, average = 'weighted')\n",
    "  r, cost = 0.2, 0.05 \n",
    "  roi = prec * r / cost\n",
    "  print(\"ROI for %s: %s \" %(name, roi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the relative ordering by ROI was the same as for precision, since the return and cost were held constant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total scoring\n",
    "Remember that precision and recall might be weighted differently and therefore the F-beta score is an important evaluation metric. Additionally, the ROC of the AUC curve is an important complementary metric to precision and recall since you saw prior how it may be the case that a model might have a high AUC but low precision. In this exercise, you will calculate the full set of evaluation metrics for each classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating classifier: Logistic Regression\n",
      "Precision: 0.7921: Recall: 0.89, F-beta score: 0.8099182004089981, AUC of ROC curve: 0.5280898876404495\n",
      "Evaluating classifier: Decision Tree\n",
      "Precision: 0.8414539007092199: Recall: 0.87, F-beta score: 0.844869431643625, AUC of ROC curve: 0.5495403472931564\n",
      "Evaluating classifier: Random Forest\n",
      "Precision: 0.8414539007092199: Recall: 0.87, F-beta score: 0.844869431643625, AUC of ROC curve: 0.5367722165474974\n",
      "Evaluating classifier: Multi-Layer Perceptron\n",
      "Precision: 0.7880208333333333: Recall: 0.85, F-beta score: 0.7996828752642706, AUC of ROC curve: 0.5566905005107252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alejandro.robles/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/alejandro.robles/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/alejandro.robles/Library/Python/3.7/lib/python/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/alejandro.robles/Library/Python/3.7/lib/python/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/alejandro.robles/Library/Python/3.7/lib/python/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/alejandro.robles/Library/Python/3.7/lib/python/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alejandro.robles/Library/Python/3.7/lib/python/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Create classifiers\n",
    "clfs = [LogisticRegression(), DecisionTreeClassifier(), RandomForestClassifier(), \n",
    "        MLPClassifier(hidden_layer_sizes = (10, ), max_iter = 50)]\n",
    "\n",
    "# Produce all evaluation metrics for each classifier\n",
    "for name, clf in zip(names, clfs):\n",
    "  print(\"Evaluating classifier: %s\" %(name))\n",
    "  y_score = clf.fit(X_train, y_train).predict_proba(X_test)\n",
    "  y_pred = clf.fit(X_train, y_train).predict(X_test)\n",
    "  prec = precision_score(y_test, y_pred, average = 'weighted')\n",
    "  recall = recall_score(y_test, y_pred, average = 'weighted')\n",
    "  fbeta = fbeta_score(y_test, y_pred, beta = 0.5, average = 'weighted')\n",
    "  roc_auc = roc_auc_score(y_test, y_score[:, 1])\n",
    "  print(\"Precision: %s: Recall: %s, F-beta score: %s, AUC of ROC curve: %s\" \n",
    "        %(prec, recall, fbeta, roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
